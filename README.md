# 跨领域句子级别中文省略消解评测（MCER2023）

* 主办单位：北京语言大学-信息科学学院-语言文化计算研究室
* 组织者：邵艳秋，李炜
* 联系方式：blcu_lcclab@163.com

[评测报名链接](https://www.wjx.cn/vm/mWoc0nZ.aspx#)

## 1 任务简介

### 任务背景

省略是一种十分常见的语言现象，在中文领域尤为普遍。对于人类而言，自然语言中存在的省略现象并不影响语义理解；但是，对于机器而言，自然语言中存在的省略现象却是语义理解类自然语言处理任务面临的挑战之一，省略现象的存在一定程度上影响着机器阅读理解、机器翻译等下游任务的准确性。然而，中文自然语言处理领域关于省略的研究十分稀少，且语言学领域并没有被广泛认可的关于“省略”的定义。因此，我们推出针对中文自然语言处理的省略定义，并依托CCL2023推出句子级别中文省略消解评测任务，希望能够引发更多对于“省略”这一语言现象的关注。

### 任务内容

本次评测分为如下2个子任务：

* 子任务1，省略位置探测：探测省略句中省略现象出现的位置
* 子任务2，省略内容补全：**从当前句子中**找到可以补全当前省略的内容

## 2 评测数据

本次评测的数据集基于我们在NLPCC2022发布的数据集 MCER: A Multi-domain Dataset for Sentence-level Chinese Ellipsis Resolution，为该数据集的2.0版本，在原有数据的基础上，本次我们又针对微博语料进行了标注，当前数据集领域分布情况如下：


| 微博 | 新闻 | 小说 | 剧本 | 教材 | 产品评论 | Total |
| ------ | ------ | :----- | ------ | ------ | :--------: | :-----: |
| 2635 | 1773 | 471  | 232  | 579  |   434   | 6124 |

我们将数据集切分为训练集、验证集、测试集和盲测集4个部分，分布情况如下：


| 数据集（Data Set） | 句子数 |
| :-------------------: | :------: |
| 训练集（Train Set） |  3674  |
|  验证集（Dev Set）  |  612  |
|  测试集（Test A）  |  919  |
|  盲测集（Test B）  |  919  |

数据样例：

```apache
{"uuid": "news_2007", "text": "中间不是没有抗拒过，我离开超视的一个原因，就是超视一位来自香港的总经理举香港电视台的《城市追击》节目为例，报导一位香港人在大陆「包二奶」，结果太太带着儿子跳楼，创下高收视率。", "targets": [{"index": "0", "content": "我"}, {"index": "53", "content": "《城市追击》"}]}
```

uuid为当前数据在数据集中的id，text为原句内容，targets中，index为省略现象出现的位置，content为这一位置应该补全的内容。（盲测集中只包含uuid和text两部分内容）

## 3 评价标准

### 子任务1：省略位置探测

1. 子任务1内容为省略位置探测，参赛者提交的结果应为整个句子中出现的所有省略现象的offset数组（对应训练数据中的index）。
2. 针对子任务1，我们主要关注Precision（P）、Recall（R）和F1值（F1）三个指标。其中 P = 正确预测出的省略位置个数/所有预测为省略的位置个数，R = 正确预测的省略位置个数/所有预测为省略位置的位置个数，F1 = 2 * P * R / （P + R）。
3. 我们将针对以上效果指标对所有题目计算平均值，作为参赛者在子任务1上的最终指标结果。

### 子任务2：省略内容补全

1. 子任务2内容为省略内容补全，参赛者提交的结果应为子任务1中预测出的省略位置和其对应的补全内容所组成的二元组。
2. 针对子任务2，我们主要关注以下几个指标：ROUGE-1、ROUGE-2、ROUGE-L以及Exact-match-score。其中ROUGE-1 = 预测结果与正确答案重合的1-gram个数/正确答案的1-gram总数，ROUGE-2 = 预测结果与正确答案重合的2-gram个数/正确答案的2-gram总数，ROUGE-L = 最长公共子序列长度/正确答案的总长度，Exact-match-score = 与正确答案完全一致的预测结果个数/预测结果总数。
3. 我们将针对以上效果指标对所有题目计算平均值，作为参赛者在子任务2上的最终指标结果。

### 综合评分标准

1. 我们将取F1值作为子任务1的最终得分
2. 子任务2的最终得分：score2 = 0.4 * Exact-match-score + 0.3 * ROUGE-L + 0.2 * ROUGE-2 + 0.1 * ROUGE-1
3. 两个子任务的平均分将作为整个任务的综合得分

### 结果提交

参赛队伍提交的结果，可以参考训练集的数据格式。

## 4 评测赛程


|            时间            |                    事项                    |
| :--------------------------: | :------------------------------------------: |
| 2023年4月1日-2023年5月15日 |                  开放报名                  |
|        2023年6月1日        |                 盲测集发布                 |
|        2023年6月5日        | 参赛队提交盲测集省略现象自动探测及补全结果 |
|       2023年6月12日       |               发布盲测集答案               |
|       2023年6月25日       |        参赛队提交中文或英文技术报告        |
|       2023年6月28日       |           中文或英文技术报告反馈           |
|        2023年7月3日        |           正式提交中英文评测论文           |
|        2023年7月7日        |                公布获奖名单                |
|       2023年7月10日       |              评测论文录用通知              |
|       2023年7月15日       |            论文Camera Ready提交            |
|       2023年8月3-5日       |   CCL2023评测研讨会：获奖队伍做技术报告   |

## 5 报名方式

点击[评测报名链接](https://www.wjx.cn/vm/mWoc0nZ.aspx#)进行报名

## 6 奖项设置

中文信息学会为本次评测获奖队伍提供的荣誉证书
